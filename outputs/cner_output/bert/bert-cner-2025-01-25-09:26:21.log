Process rank: -1, device: cpu, n_gpu: 0, distributed training: False, 16-bits training: False
Training/evaluation parameters Namespace(adam_epsilon=1e-08, adv_epsilon=1.0, adv_name='word_embeddings', cache_dir='', config_name='', crf_learning_rate=0.001, data_dir='/Users/ez/Downloads/BERT-NER-Pytorch-master/datasets/cner/', device=device(type='cpu'), do_adv=False, do_eval=True, do_lower_case=True, do_predict=False, do_train=True, eval_all_checkpoints=False, eval_max_seq_length=512, evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, id2label={0: 'B-HCCX', 1: 'B-HPPX', 2: 'B-MISC', 3: 'B-XH', 4: 'I-HCCX', 5: 'I-HPPX', 6: 'I-MISC', 7: 'I-XH', 8: 'O'}, label2id={'B-HCCX': 0, 'B-HPPX': 1, 'B-MISC': 2, 'B-XH': 3, 'I-HCCX': 4, 'I-HPPX': 5, 'I-MISC': 6, 'I-XH': 7, 'O': 8}, learning_rate=3e-05, local_rank=-1, logging_steps=-1, loss_type='ce', markup='bios', max_grad_norm=1.0, max_steps=-1, model_name_or_path='/Users/ez/Downloads/BERT-NER-Pytorch-master/bert-base-chinese', model_type='bert', n_gpu=0, no_cuda=False, num_train_epochs=4.0, output_dir='/Users/ez/Downloads/BERT-NER-Pytorch-master/outputs/cner_output/bert', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=24, per_gpu_train_batch_size=24, predict_checkpoints=0, save_steps=-1, seed=42, server_ip='', server_port='', task_name='cner', tokenizer_name='', train_max_seq_length=128, warmup_proportion=0.1, weight_decay=0.01)
Creating features from dataset file at /Users/ez/Downloads/BERT-NER-Pytorch-master/datasets/cner/
Processing example 0 of 5999
